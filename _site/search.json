[
  {
    "objectID": "posts/2020-10-26-great-american-beer-festival/index.html#background",
    "href": "posts/2020-10-26-great-american-beer-festival/index.html#background",
    "title": "Great American Beer Festival",
    "section": "Background",
    "text": "Background\n\nTidy Tuesday\nI give the same boiler plate on every Tidy Tuesday, post so skip ahead if you have read any. Tidy Tuesday is a weekly social data project in the R for Data Science community where R users explore a new dataset and share their findings. If you‚Äôre an R user (or aspiring) I highly recommend participating. A few specific Tidy Tuesday resources I‚Äôd recommend are David Robinson‚Äôs Tidy Tuesday screen casts, Twitter #TidyTuesday, and the TidyTuesday podcast with Jon Harmon. All Tidy Tuesday datasets are available on Github.\n\n\nThe Great American Beer Festival\nIn this installation, we‚Äôre analyzing data from The Great American Beer Festival. The Great American Beer Festival (GABF) is a three-day annual festival in Denver, Colorado. Judges evaluate several thousand beers entered by hundreds of breweries and award gold, silver, and bronze medals in 100+ categories - though not every medal is necessarily awarded in each category. GABF was founded in 1982 and had 22 participating breweries in the first year. To download the data I use the tidytuesdayR package."
  },
  {
    "objectID": "posts/2020-10-26-great-american-beer-festival/index.html#analysis",
    "href": "posts/2020-10-26-great-american-beer-festival/index.html#analysis",
    "title": "Great American Beer Festival",
    "section": "Analysis",
    "text": "Analysis\nThe GABF data set has an observation (row) for each beer that received an award for each year it received one. The obvious challenge with that is the dataset only includes beers awarded - it provides no data regarding participation. Without participation data many questions will go unanswered. We can‚Äôt infer the overall quality of beers based on total awards because we won‚Äôt know how many times they didn‚Äôt win. Huge bummer because many of the questions that came to mind when I saw the name of the dataset won‚Äôt be possible, c‚Äôest la vie.\nI summarized the data set with skimr. The output allowed me to quickly get an understanding of the dataset and identify some data cleaning tasks. The data types of the columns are all character, except year which is double. I converted medal to factor so I could more easily analyze it as an ordinal attribute. State has 52 unique values, but I spotted duplicate records due to casing (AK & Ak and WA & wa). I changed the casing in these observations bringing the number of states to 50, including Washington D.C. meaning one state has no awards. Medal is a character which makes sense, but I added a numeric version in case I want to do some weighted totals.\n\n\nCode\nskimr::skim(gabf)\n\n\n\nData summary\n\n\nName\ngabf\n\n\nNumber of rows\n4970\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmedal\n0\n1\n4\n6\n0\n3\n0\n\n\nbeer_name\n0\n1\n2\n89\n0\n3811\n0\n\n\nbrewery\n0\n1\n6\n58\n0\n1859\n0\n\n\ncity\n0\n1\n3\n44\n0\n803\n0\n\n\nstate\n0\n1\n2\n2\n0\n52\n0\n\n\ncategory\n0\n1\n4\n76\n0\n515\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n2007.88\n8.68\n1987\n2002\n2009\n2015\n2020\n‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá\n\n\n\n\n\nCode\ngabf <- gabf %>% \n  mutate(medal = fct_relevel(medal, c(\"Bronze\", \"Silver\"))) %>% \n  mutate(state = str_to_upper(state)) %>%\n  mutate(medal_numeric = if_else(medal == \"Gold\", 3, if_else(medal == \"Silver\", 2, 1)))\n\n\nI visualized awards over time and saw the dataset starts in 1987 (27 awards) and ends in 2020 (218 awards). Growth appears to be linear with only a few years that ever decreased.\n\n\nCode\ngabf %>% \n  group_by(year) %>% \n  tally() %>% \n  ggplot(aes(x = year, y = n)) +\n  geom_col(width = .75) +\n  labs(y = \"Awards\", x = \"Year\", title = \"Total Awards by Year\") +\n  theme_blog() \n\n\n\n\n\nThe annual growth in the number of awards appears to be similar for each medal class.\n\n\nCode\ngabf %>% \n  group_by(year, medal) %>% \n  tally() %>% \n  ggplot(aes(x = year, y = n, color = medal)) +\n  geom_line() +\n  labs(x = \"Year\", y = \"Awards\", color = \"Medal\", title = \"Medals by Year\") + \n  theme_blog()  \n\n\n\n\n\nThe dataset has 515 different award categories, which appear to be different categories of beer. That‚Äôs more than I expected. Looking at the top 5 categories table, the category with the most awards is the Classic Irish-Style Dry Stout with 62. That accounts for 0.01 percent of the awards and less than two awards per year - meaning there aren‚Äôt categories that have been used throughout the 34 years. Given that, the category attribute will be difficult to use because it‚Äôs probably very inconsistent year to year.\n\nTop 5 Beer Categories\n\n\nCode\ncats <- gabf %>% \n  mutate(category = forcats::fct_lump(category, n = 5)) %>% \n  group_by(category) %>% \n  tally()\nother_cat <- cats %>%\n  filter(category == \"Other\")\n\ncats %>% \n  filter(category != \"Other\") %>% \n  arrange(dplyr::desc(n)) %>% \n  bind_rows(., other_cat) %>% \n  kableExtra::kable(col.names = c(\"Category\", \"Awards\")) %>% \n  kableExtra::kable_styling(bootstrap_options = \"hover\") \n\n\n\n\n \n  \n    Category \n    Awards \n  \n \n\n  \n    Classic Irish-Style Dry Stout \n    62 \n  \n  \n    American-Style Pale Ale \n    61 \n  \n  \n    Bock \n    61 \n  \n  \n    Robust Porter \n    61 \n  \n  \n    Imperial Stout \n    60 \n  \n  \n    Other \n    4665 \n  \n\n\n\n\n\nThe other attributes in my summary table (beer_name, brewery, and city) all appear to be formatted correctly, but quite disperse I won‚Äôt inspect them any further at the moment.\nState is one attribute that seemed clean so I decided to take a closer look at that. The top 5 states account for almost 50 percent of all the awards. Two of the top five states are California and Texas, which are the two most populous states in the US.\n\n\nTop 5 States\n\n\nCode\nstates <- gabf %>%\n  mutate(state = forcats::fct_lump(state, n = 5)) %>%\n  group_by(state) %>%\n  tally()\nothers <- states %>%\n  filter(state == \"Other\")\n\nstates %>% \n  filter(state != \"Other\") %>% \n  arrange(dplyr::desc(n)) %>%\n  bind_rows(., others) %>% \n  kableExtra::kable(col.names = c(\"State\", \"Awards\")) %>% \n  kableExtra::kable_styling(bootstrap_options = \"hover\")\n\n\n\n\n \n  \n    State \n    Awards \n  \n \n\n  \n    CA \n    962 \n  \n  \n    CO \n    659 \n  \n  \n    OR \n    328 \n  \n  \n    TX \n    249 \n  \n  \n    WI \n    234 \n  \n  \n    Other \n    2538 \n  \n\n\n\n\n\nAnalyzing the states effectively will require population data to control for or consider per capita. Any mapping will require some sort of GIS data. These attributes are often packaged together because they‚Äôre used together frequently. There are a number of R libraries we can use. The most robust one I know off hand is tidycensus, which is a wrapper around the US Census Bureau‚Äôs API. I mention it for reference, but for simplicity I used albersusa. It has simple features which is the GIS data used by R‚Äôs sf package.\n\n\nJoining albersusa data\nThe albersusa usa_sf() function pulls a state dataset from the package which includes population and simple features. I wrote a function that takes a data frame, which I can reuse easily. I know I‚Äôll likely make more changes to gabf and changes after my awards_by_state function runs so create an ephemeral function just makes it a bit easier than managing multiple versions of data frames in my experience. I added some state level measurements that I assume we‚Äôd use later.\n\n\nCode\nawards_by_state <- . %>%\n  group_by(state) %>%\n  summarise(state_total_awards = n(), \n            state_total_awards_weighted = sum(medal_numeric),\n            state_years_with_awards = n_distinct(year)) %>% \n  ungroup() %>% \n  right_join(tigris::shift_geometry(albersusa::usa_sf(\"laea\")), by = c(\"state\"=\"iso_3166_2\")) %>%\n  rename(\"state_name\"=\"name\") %>% \n  mutate(state_avg_award = state_total_awards_weighted / state_total_awards,\n         state_total_awards_per_cap = (state_total_awards / pop_2014) *100000,\n         state_percent_total_awards = state_total_awards / sum(state_total_awards, na.rm = T)) %>% \n  replace_na(list(state_total_awards = 0, state_total_awards_weighted = 0, avg_award = 0, state_total_awards_per_cap = 0, state_percent_total_awards = 0, state_years_with_awards = 0)) \n\n\n\n\nState Rankings Table\nI wanted to view the state data with the populations and the new measures. I used a table view and some row-wise summaries to get more context for the top states and bottom states. I used the reactable pacakge because I could visualize row-wise summaries. It‚Äôs a lot of code, but most of it is pretty simple to adjust - I worked off of the package‚Äôs Twitter Followers demo and Women‚Äôs World Cup Predictions demo.\nThe table shows each state‚Äôs population, share of total awards, awards per capita (PC), and the average medal (Avg). The table is sorted by the awards per capita (PC). The table provides a few new insights. A few low population states (e.g.¬†Wyoming, Alaska, & Delaware) have a disproportionate number of awards. Alternatively, a few high population states are not well represented including New York, Georgia, and most of all Florida (no shock). Most states have a centered distribution of medals (average silver) with the exceptions mostly being states that have a sparse number of awards.\n\n\n\nCode\nmake_color_pal <- function(colors, bias = 1) {\n  get_color <- colorRamp(colors, bias = bias)\n  function(x) rgb(get_color(x), maxColorValue = 255)\n}\noff_rating_color <- make_color_pal(c(\"#f93014\", \"#f8fcf8\", \"#4DBE56\"), bias = 1.3)\nrating_column <- function(maxWidth = 55, ...) {\n  colDef(maxWidth = maxWidth, align = \"center\", class = \"cell number\", ...)\n}\n\ntbl <- gabf %>% \n  awards_by_state() %>% \n  select(state_name, pop_2014, state_percent_total_awards, state_total_awards_per_cap, state_avg_award) %>%\n  reactable(\n    height = 550,\n    striped = TRUE,\n    defaultPageSize = 51,\n    defaultSorted = \"state_total_awards_per_cap\",\n    defaultColDef = colDef(headerClass = \"reactable-header\", align = \"left\"),\n    columns = list(\n      state_name = colDef( \n        name = \"State\",\n        width = 150\n      ),\n      pop_2014 = colDef(\n        name = \"Population (2014)\",\n        cell = function(value) {\n          width <- paste0(value * 100 / max(.$pop_2014), \"%\")\n          value <- format(value, big.mark = \",\")\n          value <- format(value, width = 14, justify = \"right\")\n          bar <- div(\n            class = \"reactable-bar-chart\",\n            style = list(marginRight = \"6px\"),\n            div(class = \"reactable-bar\", style = list(width = width, backgroundColor = \"#3fc1c9\"))\n          )\n          div(class = \"reactable-bar-cell\", span(class = \"reactable-number\", value), bar)\n        }\n      ),\n      state_percent_total_awards = colDef(\n        name = \"Percent of Total Awards\",\n        cell = JS(\"function(cellInfo) {\n          // Format as percentage\n          const pct = (cellInfo.value * 100).toFixed(1) + '%'\n          // Pad single-digit numbers\n          let value = pct.padStart(5)\n          // Render bar chart\n          return (\n            '<div class=\\\"reactable-bar-cell\\\">' +\n              '<span class=\\\"reactable-number\\\">' + value + '</span>' +\n              '<div class=\\\"reactable-bar-chart\\\" style=\\\"background-color: #e1e1e1\\\">' +\n                '<div class=\\\"reactable-bar\\\" style=\\\"width: ' + pct + '; background-color: #fc5185\\\"></div>' +\n              '</div>' +\n            '</div>'\n          )\n        }\"),\n        html = TRUE\n      ),\n      state_total_awards_per_cap = rating_column(\n        name = \"PC\",\n        defaultSortOrder = \"desc\",\n        cell = function(value) {\n          scaled <- (value - min(.$state_total_awards_per_cap)) / (max(.$state_total_awards_per_cap) - min(.$state_total_awards_per_cap))\n          color <- off_rating_color(scaled)\n          value <- format(round(value, 1), nsmall = 1)\n          div(class = \"reactable-per-capita\", style = list(background = color), value)}\n      ),\n      state_avg_award = rating_column(\n        name = \"Avg\",\n        cell = function(value) format(round(value, digits = 2), nsmall = 2)\n      )\n    ),\n    compact = TRUE,\n    class = \"reactable-tbl\")\n\ndiv(class = \"reactable-tbl-view\",\n    div(class = \"div-subtitle\",\n        div(class = \"div-title\", \"Total GABF Awards by State, Population Adjusted (1987 - 2020)\"),\n        \"When reviewing total awards received per capita, Colorado, Wyoming, Alaska, Oregon, & Montana look like the big winners\"\n    ),\n    tbl\n)\n\n\n\n\n\nTotal GABF Awards by State, Population Adjusted (1987 - 2020)\nWhen reviewing total awards received per capita, Colorado, Wyoming, Alaska, Oregon, & Montana look like the big winners\n\n\n\n\n\n\n\nColorado is a great state for beer, but I would not expect it to be distinguished as a clear leader among the states. Similar story with Wyoming. Again, the data set does not provide information regarding participation. I suspect there is skew in the number of awards won by state because the festival is always held in Denver. Breweries located closer to Denver are more likely to participate.\nSeparately, time obviously plays a significant role that is not captured by the above table. The festival is older than most of the breweries that participated in 2020. The competition in 2020 was probably completely different, more crowded, than it was in 1987. When looking at total awards, we‚Äôre not accounting for that.\n\nBrief USA Beer History\nA little history on brewing in the US helps us better understand the time variable in the absencense of participation data. Jimmy Carter signed HR 1337 into law which made it explicitly legal to homebrew beer. When that law was passed, there were only ~50 breweries in the USA. Today, there are ~7k permitted breweries. You can read more in this interesting article on Vinepair. With that in mind, when the festival started breweries like Anheuser-Busch, Miller Brewing Company, and Coors Brewing Company controlled even more of the market share than they do today. The newcomers at that time were Boston Beer Company (i.e.¬†Sam Adams) and Alaskan Brewing Co., founded in 1984 and 1986 respectively. That history plays a significant role in our analysis because the newer breweries of today are years behind these older breweries with regard to winning awards. \n\n\n\nAnimated Map\nI visualized the award data in a Choropleth map. To capture the year data, I used gganimate to loop through and create a map for each year in a gif. To scale the color of the Choropleth by the specific year, rather than by the entire 34 years, I updated the awards_by_state function to include year (awards_by_state_year). It‚Äôs a bit of code to calculate different sums and counts for each level of aggregation and to impute records for missing years, but dplyr and tidyr do the heavy lifting. Nesting the annual observations in a data frame column keeps the data frame at 51 rows and prevents duplicating the simple features data for each year. The ggplot aesthetics will not take the nested data, but it‚Äôs easier to work with the data frame that way for other purposes and the function will probably be handy later. Below is the function spelled out.\n\n\nCode\n# Creates a column with the year total, every row with the same year has the same value\nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\")\n\n# Aggregates by year, state, and year total and counts the number of rows\nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\") %>% \n  group_by(state, year, year_total_awards) %>% \n  summarise(state_year_total_awards = n()) %>%\n  ungroup()\n\n# Joins missing states (from state.abb) and imputes the missing years and zero awards for each\nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\") %>% \n  group_by(state, year, year_total_awards) %>% \n  summarise(state_year_total_awards = n()) %>%\n  ungroup() %>% \n  full_join(tibble(state = state.abb), by = c(\"state\" = \"state\")) %>% \n  replace_na(list(year = 1987)) %>% \n  complete(state, nesting(year)) %>% \n  replace_na(list(state_year_total_awards = 0))\n\n# Imputes year_total_awards for the new years that were imputed in the last step  \nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\") %>% \n  group_by(state, year, year_total_awards) %>% \n  summarise(state_year_total_awards = n()) %>%\n  ungroup() %>% \n  full_join(tibble(state = state.abb), by = c(\"state\" = \"state\")) %>% \n  replace_na(list(year = 1987)) %>% \n  complete(state, nesting(year)) %>% \n  replace_na(list(state_year_total_awards = 0)) %>% \n  group_by(year) %>% \n  mutate(year_total_awards = max(year_total_awards, na.rm = T)) %>% \n  ungroup()\n\n# Calculate the percent of year total for each record (Choropleth fill) \nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\") %>% \n  group_by(state, year, year_total_awards) %>% \n  summarise(state_year_total_awards = n()) %>%\n  ungroup() %>% \n  full_join(tibble(state = state.abb), by = c(\"state\" = \"state\")) %>% \n  replace_na(list(year = 1987)) %>% \n  complete(state, nesting(year)) %>% \n  replace_na(list(state_year_total_awards = 0)) %>% \n  group_by(year) %>% \n  mutate(year_total_awards = max(year_total_awards, na.rm = T)) %>% \n  ungroup() %>% \n  mutate(pct_of_year_total_awards = state_year_total_awards / year_total_awards)\n\n# Finally, nest the yearly data under the state and join the albersusa data set and create the function\nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\") %>% \n  group_by(state, year, year_total_awards) %>% \n  summarise(state_year_total_awards = n()) %>%\n  ungroup() %>% \n  full_join(tibble(state = state.abb), by = c(\"state\" = \"state\")) %>% \n  replace_na(list(year = 1987)) %>% \n  complete(state, nesting(year)) %>% \n  replace_na(list(state_year_total_awards = 0)) %>% \n  group_by(year) %>% \n  mutate(year_total_awards = max(year_total_awards, na.rm = T)) %>% \n  ungroup() %>% \n  mutate(pct_of_year_total_awards = state_year_total_awards / year_total_awards) %>% \n  group_by(state) %>% \n  nest() %>%\n  right_join(tigris::shift_geometry(albersusa::usa_sf(\"laea\")), by = c(\"state\"=\"iso_3166_2\"))\n\n\nThen we can plug the function and pipeline the data frame through and into a gganimate output.\n\n\nCode\nchorpleth <- gabf %>% \n  awards_by_state_year() %>% \n  unnest(data) %>% \n  ggplot(ggplot2::aes(geometry = geometry, fill = pct_of_year_total_awards, group = year)) +\n  geom_sf() +\n  scale_fill_viridis_c(option = \"magma\", alpha = .9, begin = .1, labels = scales::percent) + \n  labs(title = 'Percent of Total Awards by State, Year: {round(frame_time,0)}', fill = \"Awards\") +\n  theme_blog(axis.text = ggplot2::element_blank(),\n             axis.ticks = ggplot2::element_blank()) +\n  transition_time(year) +\n  ease_aes('linear')\nanimate(chorpleth, fps = 5)\n\n\n\n\n\n\n\nInteractive TIE Fighter Plot & Line Chart\nLooking at the animation, you can see Wisconsin has lost a proportion of total awards over the 34 years. This view does not provide clarity regarding where those proportions are going. To see the trend of awards for the state, I visualized a logistic regression model in a TIE fighter plot. A logistic regression model provides a useful summary for the 34 years of awards for each state, but I wanted to keep the annual context so I thought the TIE fighter plot would work better accompanied with a line chart. I decided to add in dynamic highlighting so that both visuals can be used interactively. I used crosstalk and plotly to build in the interactivity. Crosstalk enables htmlwidgets with cross-widget interactions (highlighting and filtering). Plotly builds interactive graphs and the author wrote a ggplotly() function that will convert ggplot2 graphics to plotly, brilliant! Now I can build interactive data visualizations without knowing much more than ggplot.\n\n\n\nI used a number of resources to figure out how to do this. David Robinson wrote intro to broom, which covers all the needed tools to build TIE fighter plots and more. Carson Servert wrote a plotly book which covers all plotly functionality with examples. Plotly mostly handles crosstalk for the user, but I have found it easier to learn crosstalk to know what‚Äôs happening under the hood. Crosstalk relies on it‚Äôs SharedData object. Carson‚Äôs book also has a client-side linking chapter which talks through how to use crosstalk in plotly. Finally, this Stackoverflow post also provided a quick, repeatable example.\nThe widgets need two SharedData objects from gabf to cross-link the visuals. One with an observation for each state and the years and awards nested as a tibble column (TIE fighter plot). One with an observation for each state for each year with awards won (line chart). The ephemeral functions now come in handy. I can join my state level awards data with my state & year level awards data in order to filter out states with that didn‚Äôt receive awards in more than one year and states that didn‚Äôt receive more than five total awards for both SharedData objects. Below are the two SharedData objects spelled out.\n\n\nCode\n###################\n# TIE Fighter Data\n###################\n# Filter states without enough awards and remove simple features (not needed and they are heavy)\ntie_fighter_data <- . %>% \n  awards_by_state_year() %>% \n  left_join(y = gabf %>% awards_by_state()) %>%\n  select(-geometry) %>% \n  filter(state_years_with_awards > 1 & state_total_awards > 5)\n# Create a model for each state\ntie_fighter_data <- . %>% \n  awards_by_state_year() %>% \n  left_join(y = gabf %>% awards_by_state()) %>%\n  select(-geometry) %>% \n  filter(state_years_with_awards > 1 & state_total_awards > 5) %>% \n  mutate(model = map(data, ~ glm(cbind(state_year_total_awards, year_total_awards - state_year_total_awards) ~ year, data = .x , family = \"binomial\")))\n# Tidy model data \ntie_fighter_data <- . %>% \n  awards_by_state_year() %>% \n  left_join(y = gabf %>% awards_by_state()) %>%\n  select(-geometry) %>% \n  filter(state_years_with_awards > 1 & state_total_awards > 5) %>% \n  mutate(model = map(data, ~ glm(cbind(state_year_total_awards, year_total_awards - state_year_total_awards) ~ year, data = .x , family = \"binomial\"))) %>% \n  mutate(results = map(model, broom::tidy, conf.int = TRUE)) %>%\n  unnest(results) %>%\n  ungroup() %>% \n  filter(term == \"year\")\n# Reorder the data by estimate (states listed by trend)\ntie_fighter_data <- . %>% \n  awards_by_state_year() %>% \n  left_join(y = gabf %>% awards_by_state()) %>%\n  select(-geometry) %>% \n  filter(state_years_with_awards > 1 & state_total_awards > 5) %>% \n  mutate(model = map(data, ~ glm(cbind(state_year_total_awards, year_total_awards - state_year_total_awards) ~ year, data = .x , family = \"binomial\"))) %>% \n  mutate(results = map(model, broom::tidy, conf.int = TRUE)) %>%\n  unnest(results) %>%\n  ungroup() %>% \n  filter(term == \"year\") %>% \n  mutate(state = fct_reorder(state, estimate))\n# Add attributes for plot formatting and tooltip\ntie_fighter_data <- . %>% \n  awards_by_state_year() %>% \n  left_join(y = gabf %>% awards_by_state()) %>%\n  select(-geometry) %>% \n  filter(state_years_with_awards > 1 & state_total_awards > 5) %>% \n  mutate(model = map(data, ~ glm(cbind(state_year_total_awards, year_total_awards - state_year_total_awards) ~ year, data = .x , family = \"binomial\"))) %>% \n  mutate(results = map(model, broom::tidy, conf.int = TRUE)) %>%\n  unnest(results) %>%\n  ungroup() %>% \n  filter(term == \"year\") %>% \n  mutate(state = fct_reorder(state, estimate)) %>% \n  mutate(p_value = case_when(\n    p.value >= .075 ~ \"not confident\",\n    p.value >= .025 ~ \"somewhat confident\",\n    p.value < .025 ~ \"confident\"),\n    trend = case_when(\n      estimate >= .0025 ~ \"trending up\",\n      estimate < -.0025 ~ \"trending down\",\n      T  ~ \"flat\"\n      )) %>%\n  mutate(p_value = fct_relevel(p_value, c(\"not confident\", \"somewhat confident\")))\n# Create the SharedData object\ntie_fighter_data <- . %>% \n  awards_by_state_year() %>% \n  left_join(y = gabf %>% awards_by_state()) %>%\n  select(-geometry) %>% \n  filter(state_years_with_awards > 1 & state_total_awards > 5) %>% \n  mutate(model = map(data, ~ glm(cbind(state_year_total_awards, year_total_awards - state_year_total_awards) ~ year, data = .x , family = \"binomial\"))) %>% \n  mutate(results = map(model, broom::tidy, conf.int = TRUE)) %>%\n  unnest(results) %>%\n  ungroup() %>% \n  filter(term == \"year\") %>% \n  mutate(state = fct_reorder(state, estimate)) %>% \n  mutate(p_value = case_when(\n    p.value >= .075 ~ \"not confident\",\n    p.value >= .025 ~ \"somewhat confident\",\n    p.value < .025 ~ \"confident\"),\n    trend = case_when(\n      estimate >= .0025 ~ \"trending up\",\n      estimate < -.0025 ~ \"trending down\",\n      T  ~ \"flat\")) %>%\n  mutate(p_value = fct_relevel(p_value, c(\"not confident\", \"somewhat confident\"))) %>% \n  SharedData$new(key = ~state_name, group = \"Choose states (hold shift to select multiple):\")\n  \n###################\n# Line Chart Data\n###################\n# Filter states without enough awards and remove simple features (not needed and they are heavy)\nline_chart_data <- . %>% \n  awards_by_state_year() %>% \n  left_join(y = gabf %>% awards_by_state()) %>%\n  select(-geometry) %>% \n  filter(state_years_with_awards > 1 & state_total_awards > 5)\n# Unnest the annual observations for ggplot aesthetics\nline_chart_data <- . %>% \n  awards_by_state_year() %>% \n  left_join(y = gabf %>% awards_by_state()) %>%\n  select(-geometry) %>% \n  filter(state_years_with_awards > 1 & state_total_awards > 5) %>% \n  unnest(data)\n# Create the SharedData object\nline_chart_data <- . %>% \n  awards_by_state_year() %>% \n  left_join(y = gabf %>% awards_by_state()) %>%\n  select(-geometry) %>% \n  filter(state_years_with_awards > 1 & state_total_awards > 5) %>% \n  unnest(data) %>% \n  SharedData$new(key = ~state_name, group = \"Choose states (hold shift to select multiple):\")\n\n\nAgain just use the functions in a pipeline into ggplot and pass the ggplot objects to ggplotly. Most of the ggplot code is straight forward if you‚Äôre a ggplot user, but the text aesthetic is a bit of a blob. That‚Äôs because ggplotly allows aesthetics to be set in the tool tip using tooltip = \"text\". So if you paste together data and html tags you can build a nice tool tip. It‚Äôs tedious, but useful. Finally, subplot ties the plots together in a view with highlighting. Just a heads up - if you use htmlwidgets in a blogdown site, css classes can start bumping into another. Objects can disappear simply because the css container is smaller the the htmlwidget, use your browser tools to reset sizing and debug.\n\n\n\nCode\ngreys <- brewer.pal(n = 9, \"Greys\")\ngreys <- c(greys[3], greys[6], greys[9])\ntie_fighter_plot <- gabf %>% \n  tie_fighter_data() %>% \n  ggplot(aes(x = estimate, y = state, key = state_name, group = state_total_awards, color = p_value,\n             text = paste0(\"<b>\", state_name, \"</b>\\n\", if_else(p_value == 'confident', glue('P-Value: {format(round(p.value, digits = 4), nsmall = 4)}\\nThe number of {state_name} awards is definitely {trend}.'), \n                                                                      if_else(p_value == 'somewhat confident', glue::glue(\"'P-Value: {format(round(p.value, digits = 4), nsmall = 4)}\\nThe number of {state_name} awards is {trend}, but there is some uncertainty.\"), glue::glue(\"P-Value: {format(round(p.value, digits = 4), nsmall = 4)}\\nThe number of {state_name} awards appears to be {trend}, but there is signficant uncertainty.\"))))), \n         guides = guides(color = NULL)) +\n  geom_point(size = 1.75) +\n  geom_errorbarh(aes(\n    xmin = conf.low,\n    xmax = conf.high),\n  height = .5,\n  size = 1,\n  show.legend = FALSE) +\n  geom_vline(xintercept = 0, lty = 2, color = \"#a0aace\") +\n  scale_colour_manual(values = greys) +\n  scale_x_continuous(limits = c(-0.15, 0.15), \n                     breaks = c(-.1, 0, .1),\n                     labels = c(\"Descreasing\", \"\", \"Increasing\")) +\n  labs(\n    x = \"Trend\",\n    title = NULL,\n    y = NULL,\n    color = NULL) +\n  theme_blog()\ntie_fighter_plot <- plotly::ggplotly(tie_fighter_plot, tooltip = \"text\", height = 625)\nline_chart <- gabf %>% \n  line_chart_data() %>% \n  ggplot(aes(x = year, y = state_year_total_awards, key = state_name, group = state_total_awards,\n             text = glue::glue(\"<b>{state_name} Awards</b>\\n{state_year_total_awards} ({year})\\n{state_total_awards} (1987-2020)\\n\"))) +\n  geom_line() +\n  labs(\n    x = \"Year\",\n    title = NULL,\n    y = \"\") +\n  theme_blog(panel.grid.major.y = element_blank())\nline_chart <- ggplotly(line_chart, tooltip = \"text\", height = 625)  \nlinked_plots <- subplot(tie_fighter_plot,\n                        line_chart,\n                        widths = c(.35, .65)) %>%\n  layout(showlegend = FALSE) %>% \n  highlight(on = \"plotly_click\", selectize = TRUE, dynamic = T)\ndiv(class = \"subplot-view\",\n    div(class = \"div-subtitle\",\n        div(class = \"div-title\", \"State Trends\"),\n        \"Alaska & Wisconsin are losing their share of awards to North Carolina, Indiana, & Virginia with South Carolina Jumping in the mix. California, Oregon, & Colorado appear to be maintaining their hold on the lion's share of the awards.\"\n    ),\n    linked_plots\n)\n\n\n\n\nState Trends\nAlaska & Wisconsin are losing their share of awards to North Carolina, Indiana, & Virginia with South Carolina Jumping in the mix. California, Oregon, & Colorado appear to be maintaining their hold on the lion's share of the awards.\n\n\n\n\n\n\n\nLooking at the results (State Trends), the TIE fighter plot (on the left) shows the model results by state. The states with points further to the right are seeing an upward trend in the number of awards received, states to the left are seeing a downward trend. The lines (error bars) show the confidence intervals of the model. Darker colored TIE fighter‚Äôs have higher p-values (more certainty). The line chart (on the right) shows each state with the number of awards over the 34 years. Hover on a TIE fighter or line, the hover-link provides helpful text. Highlight any state by clicking on its TIE fighter or line, or just type the state in the search bar at the top. Multi-select states with shift, but it‚Äôs a bit shifty (pun intended). When selecting multiple states, change the brush color to make it easier to see which state is which.\n\n\nBrewery, Category, & Beer Table\nOur logistic regression model provides a great understanding of how states are preforming, what about breweries or beers? This is where the data set starts to get dirty, I‚Äôll walk through a few of the issues using the first record in the table below (Beer Name == \"Oktoberfest\"). There are duplicate beer names across breweries. For example, there are 18 beers called Oktoberfest, which won 20 total medals. Since they aren‚Äôt unique, the data would need to be grouped on another attribute. Brewery would be the obvious choice, but drill down into the nested table and you will quickly spot duplicated brewery names with slight spelling variations (e.g.¬†Stoudts Brewing Co. and Stoudt's Brewing Co.). This is pervasive upon inspecting other examples. The category on the other hand seems to have evolved rapidly or beers can enter multiple categories. The Oktoberfest beers have 10 different categories and Stoudt‚Äôs Oktoberfest (which is the exact same beer) has competed in two different categories. Categories also have some character issues, for example (the German-Style MC3=A4rzen is German-Style M√§erzen, the √§ causes the characters). I can clean those up, but it‚Äôd be a bit of work.\n\n\n\nCode\ntbl <- gabf %>% \n  count(beer_name, brewery, category, medal) %>% \n  mutate(beer_name = fct_reorder(beer_name, n, sum)) %>% \n  pivot_wider(names_from = medal, values_from = n, values_fill = 0) %>% \n  mutate(total_medals = Gold+Silver+Bronze) %>% \n  clean_names(\"title\") %>% \n  reactable(groupBy = \"Beer Name\",\n            defaultPageSize = 5,\n            filterable = TRUE, \n            searchable = TRUE,\n            defaultSorted = c(\"Total Medals\"),\n            defaultSortOrder = \"desc\",\n            showPageSizeOptions = TRUE,\n            class = \"reactable-tbl\",\n            defaultColDef = colDef(aggregate = \"sum\", headerClass = \"reactable-header\", align = \"left\"),\n            compact = TRUE,\n            columns =  list(\n              Brewery = colDef(\n                name = \"Breweries\",\n                aggregate = JS(\"\n                function(values, rows) \n                {\n                  let breweries = values.filter((e, i) => values.indexOf(e) === i);\n                  if(breweries.length > 1){\n                    var left = '(';\n                    var right = ')';\n                    return breweries.length;\n                  } else {\n                    return breweries;\n                  }\n                }\")\n              ),\n              Category = colDef(\n                name = \"Categories\",\n                aggregate = JS(\"\n                function(values, rows) \n                {\n                  let categories = values.filter((e, i) => values.indexOf(e) === i);\n                  if(categories.length > 1){\n                    return categories.length;\n                  } else {\n                    return categories;\n                  }\n                }\")\n              ),\n              `Category Total` = colDef(\n                aggregate = \"max\"\n              ),\n              Gold = colDef( \n                name = \"Total Golds\"\n              ),\n              Silver = colDef( \n                name = \"Total Silvers\"\n              ),\n              Bronze = colDef( \n                name = \"Total Bronzes\"\n              )))\ndiv(class = \"reactable-tbl-view\",\n    div(class = \"div-subtitle\",\n        div(class = \"div-title\", \"All GABF Award Winning Beers \"),\n        \"Data is nested on beers, exploring the data shows a number of data cleaning activities required\"\n    ),\n    tbl\n)\n\n\n\n\n\nAll GABF Award Winning Beers \nData is nested on beers, exploring the data shows a number of data cleaning activities required\n\n\n\n\n\n\n\n\n\nAward Winning Categories by State\nCleaning up some of the text data would be cumbersome and I don‚Äôt want to invest all that additional time at this point. Given that, I‚Äôm going to focus on getting insights from the category data. Although it‚Äôs shifted a lot over the years, it seems to be the cleanest by far. The tidylo package can measure the which categories are most likely to get an award by state even and it deals with the different states have different numbers of awards. I recommend Julia & Tyler‚Äôs article on the package site if you want to learn more.\nThe visual below shows which categories are most likely to get an award by state (bars that go to the right) and which categories are least likely (bars that go to the left) based on the historical data. I‚Äôm a big fan of stouts, porters, and sours which tend to be hard to find in certain states. Wisconsin and Illinois being less represented in those categories makes a lot of sense given all the love they give to German beer.\n\n\n\nCode\ngabf %>% \n  filter(fct_lump(state, 9) != \"Other\",\n         fct_lump(category, 7) != \"Other\") %>%\n  count(state, category) %>% \n  complete(state, category, fill = list(n = 0)) %>% \n  bind_log_odds(state, category, n) %>% \n  mutate(category = reorder_within(category, log_odds_weighted, state),\n         state = fct_reorder(state, -n)) %>% \n  arrange(desc(n)) %>% \n  ggplot(aes(log_odds_weighted, category)) +\n  geom_col() +\n  labs(title = \"Most Award Winning Categories by State\", x = NULL, y = \"Category\") +\n  scale_y_reordered() +\n  facet_wrap(~state, scales = \"free_y\", nrow = 3) +\n  theme_blog_facet(axis.text.x = element_blank(), axis.ticks.x = element_blank())"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Mark Druffel",
    "section": "",
    "text": "Hi There!\nI‚Äôm a data scientist, I mutate ‚òï + üç∫ into  code.\n\n\n\nMotivation\nData science and technology are constantly evolving and keeping up can be difficult. I set up this blog as a tool to share some of the things I‚Äôve learned with others and for my own posterity. R is my favorite data science language so most of my posts are written in R, but I also use Python, ,SQL, and others regularly so I try to share content regarding those as well.\n\n\n\nA bit about me\nCurrently, I am a lead data scientist at 84.51¬∞. I live in Portland, OR with my amazing wife Brittany and our two kids. When I‚Äôm not working with data, I love to cook, hike, rock-climb, play video games, travel, and explore the Pacific-Northwest.\n\nIf you ever have questions about a post or want to connect, please don‚Äôt hesitate to reach out!"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Great American Beer Festival\n\n\nTidy Tuesday analysis of the Great American Beer Festival winners from 1987 to 2020.\n\n\n\n\ntidy-tuesday\n\n\n\n\n\n\n\n\n\n\n\nOct 26, 2020\n\n\nMark Druffel\n\n\n\n\n\n\n  \n\n\n\n\nHello World\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 21, 2019\n\n\nMark Druffel\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2019-12-21-hello-world/index.html",
    "href": "posts/2019-12-21-hello-world/index.html",
    "title": "Hello World",
    "section": "",
    "text": "At this year‚Äôs RStudio Conf David Robinson discussed the importance of sharing work publicly in his talk ‚ÄúThe unreasonable effectiveness of public work.‚Äù. He attributed much of his own personal, professional success to the habit of sharing his work and encouraged others to adopt the habit. I recommend the talk to anyone, data scientist or not. Anyhow, I have procrastinated writing a blog for long enough. I attended the Advanced RMarkdown Workshop at the conference and learned, among other things, the blogdown blogdown package so here‚Äôs to getting started :beers:"
  },
  {
    "objectID": "posts/2019-12-21-hello-world/index.html#blogdown-starter-kit",
    "href": "posts/2019-12-21-hello-world/index.html#blogdown-starter-kit",
    "title": "Hello World",
    "section": "Blogdown Starter Kit",
    "text": "Blogdown Starter Kit\nThe aforementioned Advanced RMarkdown Workshop is a great resource and per usual RStudio was kind enough to open source it. A few additional resource I used to get this site open and running were:\n\nRbind Github Repo\nUp & Running with blogdown\nMaking a Website Using Blogdown, Hugo, and GitHub Pages\nRstudio Conf: Making Websites in R Markdown\nblogdown: Creating Websites with R Markdown\nSetting up your blog with RStudio and blogdown:\n\nPart I: Creating the blog\nPart II: Workflow\nPart III: Modify Your Theme\n\nMarkdown Basics\nR Markdown the Definitive Guide\nHugo Emojify Cheatsheet\n\nAll the above resources should have anyone well informed on blogdown, but for posterity I recommend following Alison Hill‚Äôs blog as there are sure to be updates and she is an amazing resource. Happy blogging!"
  },
  {
    "objectID": "posts/2020-10-26-great-american-beer-festival/index.html#wrapping-up",
    "href": "posts/2020-10-26-great-american-beer-festival/index.html#wrapping-up",
    "title": "Great American Beer Festival",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nThis data set would have been a lot more interesting if we had the full participation list. That being said, there were some interesting findings.\nI went down a few rabbit holes that I did not write-up. I built a sunburst of the year, brewery, category, and beers just to explore the data more easily, but it was too difficult to read even after applying factor lumping - the data is just too disperse (i.e.¬†too many unique values for each category). In order to make the sunburst usable I thought it would be helpful to build another cross-widget interaction to navigate the first few categories so they could be left off of the sunburst, but but it turns out sunburstR does not support crosstalk at the moment (side note, if you have not used sunburstR it makes beautiful d3.js sunbursts with very little effort). I had a quick conversation with one of the package maintainers and it sounds like it would be a significant effort to add that functionality - would be a super interesting project. I also tried to figure out how to clean up the character issues such as √§, but I couldn‚Äôt find any simple tools to use for that specific issue - would be interesting to research further.\nAside from those rabbit holes, the state rankings table provided interesting insights regarding awards per capita with Colorado way out in front. The TIE fighter plot showed that some lesser expected states including the Carolinas are catching up in the number of awards. The award winning categories by state log odds plot showed that, by in large, states win awards in different categories when comparing to each other.\nThanks for reading and if you have any feedback please do post it below or feel free to reach out to me directly (contact info is at the bottom)!"
  }
]