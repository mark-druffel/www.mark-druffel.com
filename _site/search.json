[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2022\n\n\nTristan O‚ÄôMalley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Mark Druffel",
    "section": "",
    "text": "Hi There!\nI‚Äôm a data scientist, I mutate ‚òï + üç∫ into  code.\n\n\nMotivation\nLike many data scientists, I started without formal training so I spent a lot of time learning. I set up this blog as a tool to share some of the things I‚Äôve learned and connect with others.\n\n\nA bit about me\nCurrently, I am a lead data scientist at 84.51¬∞. I live in Portland, OR with my amazing wife Brittany and our two kids. When I‚Äôm not working with data, I love to cook, hike, rock-climb, play video games, travel, and explore the Pacific-Northwest.\nIf you ever have questions about a post or want to connect, please don‚Äôt hesitate to reach out!"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Great American Beer Festival\n\n\nTidy Tuesday analysis of the Great American Beer Festival winners from 1987 to 2020.\n\n\n\n\ntidy-tuesday\n\n\n\n\n\n\n\n\n\n\n\nOct 26, 2020\n\n\nMark Druffel\n\n\n\n\n\n\n  \n\n\n\n\nHello World\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 21, 2019\n\n\nMark Druffel\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "pages/about.html",
    "href": "pages/about.html",
    "title": "Mark Druffel",
    "section": "",
    "text": "Hi There!\nI‚Äôm a data scientist, I mutate ‚òï + üç∫ into  code.\n\n\nMotivation\nLike many data scientists, I started without formal training so I spent a lot of time learning. I set up this blog as a tool to share some of the things I‚Äôve learned and connect with others.\n\n\nA bit about me\nToday, I am a lead data scientist at 84.51¬∞. I live in Portland, OR with my amazing wife Brittany and our two kids. I have too many hobbies including cooking, hiking, rock-climbing, gaming, traveling, and exploring the Pacific-Northwest üóª\nIf you ever have questions about a post or want to connect, please don‚Äôt hesitate to reach out! - Mark"
  },
  {
    "objectID": "pages/blog.html",
    "href": "pages/blog.html",
    "title": "Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "home.html",
    "href": "home.html",
    "title": "Mark Druffel",
    "section": "",
    "text": "2\n\n\n3"
  },
  {
    "objectID": "posts/2020-10-26-great-american-beer-festival/index.html#background",
    "href": "posts/2020-10-26-great-american-beer-festival/index.html#background",
    "title": "Great American Beer Festival",
    "section": "Background",
    "text": "Background\n\nTidy Tuesday\nI give the same boiler plate on every Tidy Tuesday, post so skip ahead if you have read any. Tidy Tuesday is a weekly social data project in the R for Data Science community where R users explore a new dataset and share their findings. If you‚Äôre an R user (or aspiring) I highly recommend participating. A few specific Tidy Tuesday resources I‚Äôd recommend are David Robinson‚Äôs Tidy Tuesday screen casts, Twitter #TidyTuesday, and the TidyTuesday podcast with Jon Harmon. All Tidy Tuesday datasets are available on Github.\n\n\nThe Great American Beer Festival\nIn this installation, we‚Äôre analyzing data from The Great American Beer Festival. The Great American Beer Festival (GABF) is a three-day annual festival in Denver, Colorado. Judges evaluate several thousand beers entered by hundreds of breweries and award gold, silver, and bronze medals in 100+ categories - though not every medal is necessarily awarded in each category. GABF was founded in 1982 and had 22 participating breweries in the first year. To download the data I use the tidytuesdayR package."
  },
  {
    "objectID": "posts/2020-10-26-great-american-beer-festival/index.html#analysis",
    "href": "posts/2020-10-26-great-american-beer-festival/index.html#analysis",
    "title": "Great American Beer Festival",
    "section": "Analysis",
    "text": "Analysis\nThe GABF data set has an observation (row) for each beer that received an award for each year it received one. The obvious challenge with that is the dataset only includes beers awarded - it provides no data regarding participation. Without participation data many questions will go unanswered. We can‚Äôt infer the overall quality of beers based on total awards because we won‚Äôt know how many times they didn‚Äôt win. Huge bummer because many of the questions that came to mind when I saw the name of the dataset won‚Äôt be possible, c‚Äôest la vie.\nI summarized the data set with skimr. The output allowed me to quickly get an understanding of the dataset and identify some data cleaning tasks. The data types of the columns are all character, except year which is double. I converted medal to factor so I could more easily analyze it as an ordinal attribute. State has 52 unique values, but I spotted duplicate records due to casing (AK & Ak and WA & wa). I changed the casing in these observations bringing the number of states to 50, including Washington D.C. meaning one state has no awards. Medal is a character which makes sense, but I added a numeric version in case I want to do some weighted totals.\n\nskimr::skim(gabf)\n\n\nData summary\n\n\nName\ngabf\n\n\nNumber of rows\n4970\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmedal\n0\n1\n4\n6\n0\n3\n0\n\n\nbeer_name\n0\n1\n2\n89\n0\n3811\n0\n\n\nbrewery\n0\n1\n6\n58\n0\n1859\n0\n\n\ncity\n0\n1\n3\n44\n0\n803\n0\n\n\nstate\n0\n1\n2\n2\n0\n52\n0\n\n\ncategory\n0\n1\n4\n76\n0\n515\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n2007.88\n8.68\n1987\n2002\n2009\n2015\n2020\n‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá\n\n\n\n\ngabf <- gabf %>% \n  mutate(medal = fct_relevel(medal, c(\"Bronze\", \"Silver\"))) %>% \n  mutate(state = str_to_upper(state)) %>%\n  mutate(medal_numeric = if_else(medal == \"Gold\", 3, if_else(medal == \"Silver\", 2, 1)))\n\nI visualized awards over time and saw the dataset starts in 1987 (27 awards) and ends in 2020 (218 awards). Growth appears to be linear with only a few years that ever decreased.\n\ngabf %>% \n  group_by(year) %>% \n  tally() %>% \n  ggplot(aes(x = year, y = n)) +\n  geom_col(width = .75) +\n  labs(y = \"Awards\", x = \"Year\", title = \"Total Awards by Year\") +\n  theme_blog() \n\n\n\n\nThe annual growth in the number of awards appears to be similar for each medal class.\n\ngabf %>% \n  group_by(year, medal) %>% \n  tally() %>% \n  ggplot(aes(x = year, y = n, color = medal)) +\n  geom_line() +\n  labs(x = \"Year\", y = \"Awards\", color = \"Medal\", title = \"Medals by Year\") + \n  theme_blog()  \n\n\n\n\nThe dataset has 515 different award categories, which appear to be different categories of beer. That‚Äôs more than I expected. Looking at the top 5 categories table, the category with the most awards is the Classic Irish-Style Dry Stout with 62. That accounts for 0.01 percent of the awards and less than two awards per year - meaning there aren‚Äôt categories that have been used throughout the 34 years. Given that, the category attribute will be difficult to use because it‚Äôs probably very inconsistent year to year.\n\nTop 5 Beer Categories\n\ncats <- gabf %>% \n  mutate(category = forcats::fct_lump(category, n = 5)) %>% \n  group_by(category) %>% \n  tally()\nother_cat <- cats %>%\n  filter(category == \"Other\")\n\ncats %>% \n  filter(category != \"Other\") %>% \n  arrange(dplyr::desc(n)) %>% \n  bind_rows(., other_cat) %>% \n  kableExtra::kable(col.names = c(\"Category\", \"Awards\")) %>% \n  kableExtra::kable_styling(bootstrap_options = \"hover\") \n\n\n\n \n  \n    Category \n    Awards \n  \n \n\n  \n    Classic Irish-Style Dry Stout \n    62 \n  \n  \n    American-Style Pale Ale \n    61 \n  \n  \n    Bock \n    61 \n  \n  \n    Robust Porter \n    61 \n  \n  \n    Imperial Stout \n    60 \n  \n  \n    Other \n    4665 \n  \n\n\n\n\n\nThe other attributes in my summary table (beer_name, brewery, and city) all appear to be formatted correctly, but quite disperse I won‚Äôt inspect them any further at the moment.\nState is one attribute that seemed clean so I decided to take a closer look at that. The top 5 states account for almost 50 percent of all the awards. Two of the top five states are California and Texas, which are the two most populous states in the US.\n\n\nTop 5 States\n\nstates <- gabf %>%\n  mutate(state = forcats::fct_lump(state, n = 5)) %>%\n  group_by(state) %>%\n  tally()\nothers <- states %>%\n  filter(state == \"Other\")\n\nstates %>% \n  filter(state != \"Other\") %>% \n  arrange(dplyr::desc(n)) %>%\n  bind_rows(., others) %>% \n  kableExtra::kable(col.names = c(\"State\", \"Awards\")) %>% \n  kableExtra::kable_styling(bootstrap_options = \"hover\")\n\n\n\n \n  \n    State \n    Awards \n  \n \n\n  \n    CA \n    962 \n  \n  \n    CO \n    659 \n  \n  \n    OR \n    328 \n  \n  \n    TX \n    249 \n  \n  \n    WI \n    234 \n  \n  \n    Other \n    2538 \n  \n\n\n\n\n\nAnalyzing the states effectively will require population data to control for or consider per capita. Any mapping will require some sort of GIS data. These attributes are often packaged together because they‚Äôre used together frequently. There are a number of R libraries we can use. The most robust one I know off hand is tidycensus, which is a wrapper around the US Census Bureau‚Äôs API. I mention it for reference, but for simplicity I used albersusa. It has simple features which is the GIS data used by R‚Äôs sf package.\n\n\nJoining alberusa data\nThe albersa usa_sf() function pulls a state dataset from the package which includes population and simple features. I wrote a function that takes a data frame, which I can reuse easily. I know I‚Äôll likely make more changes to gabf and changes after my awards_by_state function runs so create an ephemeral function just makes it a bit easier than managing multiple versions of data frames in my experience. I added some state level measurements that I assume we‚Äôd use later.\n\nawards_by_state <- . %>%\n  group_by(state) %>%\n  summarise(state_total_awards = n(), \n            state_total_awards_weighted = sum(medal_numeric),\n            state_years_with_awards = n_distinct(year)) %>% \n  ungroup() %>% \n  right_join(albersusa::usa_sf(\"laea\"), by = c(\"state\"=\"iso_3166_2\")) %>%\n  rename(\"state_name\"=\"name\") %>% \n  mutate(state_avg_award = state_total_awards_weighted / state_total_awards,\n         state_total_awards_per_cap = (state_total_awards / pop_2014) *100000,\n         state_percent_total_awards = state_total_awards / sum(state_total_awards, na.rm = T)) %>% \n  replace_na(list(state_total_awards = 0, state_total_awards_weighted = 0, avg_award = 0, state_total_awards_per_cap = 0, state_percent_total_awards = 0, state_years_with_awards = 0)) \n\n\n\nState Rankings Table\nI wanted to view the state data with the populations and the new measures. I used a table view and some row-wise summaries to get more context for the top states and bottom states. I used the reactable pacakge because I could visualize row-wise summaries. It‚Äôs a lot of code, but most of it is pretty simple to adjust - I worked off of the package‚Äôs Twitter Followers demo and Women‚Äôs World Cup Predictions demo.\nThe table shows each state‚Äôs population, share of total awards, awards per capita (PC), and the average medal (Avg). The table is sorted by the awards per capita (PC). The table provides a few new insights. A few low population states (e.g.¬†Wyoming, Alaska, & Delaware) have a disproportionate number of awards. Alternatively, a few high population states are not well represented including New York, Georgia, and most of all Florida (no shock). Most states have a centered distribution of medals (average silver) with the exceptions mostly being states that have a sparse number of awards.\n\nmake_color_pal <- function(colors, bias = 1) {\n  get_color <- colorRamp(colors, bias = bias)\n  function(x) rgb(get_color(x), maxColorValue = 255)\n}\noff_rating_color <- make_color_pal(c(\"#f93014\", \"#f8fcf8\", \"#4DBE56\"), bias = 1.3)\nrating_column <- function(maxWidth = 55, ...) {\n  colDef(maxWidth = maxWidth, align = \"center\", class = \"cell number\", ...)\n}\n\ntbl <- gabf %>% \n  awards_by_state() %>% \n  select(state_name, pop_2014, state_percent_total_awards, state_total_awards_per_cap, state_avg_award) %>%\n  reactable(\n    height = 550,\n    striped = TRUE,\n    defaultPageSize = 51,\n    defaultSorted = \"state_total_awards_per_cap\",\n    defaultColDef = colDef(headerClass = \"reactable-header\", align = \"left\"),\n    columns = list(\n      state_name = colDef( \n        name = \"State\",\n        width = 150\n      ),\n      pop_2014 = colDef(\n        name = \"Population (2014)\",\n        cell = function(value) {\n          width <- paste0(value * 100 / max(.$pop_2014), \"%\")\n          value <- format(value, big.mark = \",\")\n          value <- format(value, width = 14, justify = \"right\")\n          bar <- div(\n            class = \"reactable-bar-chart\",\n            style = list(marginRight = \"6px\"),\n            div(class = \"reactable-bar\", style = list(width = width, backgroundColor = \"#3fc1c9\"))\n          )\n          div(class = \"reactable-bar-cell\", span(class = \"reactable-number\", value), bar)\n        }\n      ),\n      state_percent_total_awards = colDef(\n        name = \"Percent of Total Awards\",\n        cell = JS(\"function(cellInfo) {\n          // Format as percentage\n          const pct = (cellInfo.value * 100).toFixed(1) + '%'\n          // Pad single-digit numbers\n          let value = pct.padStart(5)\n          // Render bar chart\n          return (\n            '<div class=\\\"reactable-bar-cell\\\">' +\n              '<span class=\\\"reactable-number\\\">' + value + '</span>' +\n              '<div class=\\\"reactable-bar-chart\\\" style=\\\"background-color: #e1e1e1\\\">' +\n                '<div class=\\\"reactable-bar\\\" style=\\\"width: ' + pct + '; background-color: #fc5185\\\"></div>' +\n              '</div>' +\n            '</div>'\n          )\n        }\"),\n        html = TRUE\n      ),\n      state_total_awards_per_cap = rating_column(\n        name = \"PC\",\n        defaultSortOrder = \"desc\",\n        cell = function(value) {\n          scaled <- (value - min(.$state_total_awards_per_cap)) / (max(.$state_total_awards_per_cap) - min(.$state_total_awards_per_cap))\n          color <- off_rating_color(scaled)\n          value <- format(round(value, 1), nsmall = 1)\n          div(class = \"reactable-per-capita\", style = list(background = color), value)}\n      ),\n      state_avg_award = rating_column(\n        name = \"Avg\",\n        cell = function(value) format(round(value, digits = 2), nsmall = 2)\n      )\n    ),\n    compact = TRUE,\n    class = \"reactable-tbl\")\n\ndiv(class = \"reactable-tbl-view\",\n    div(class = \"div-subtitle\",\n        div(class = \"div-title\", \"Total GABF Awards by State, Population Adjusted (1987 - 2020)\"),\n        \"When reviewing total awards received per capita, Colorado, Wyoming, Alaska, Oregon, & Montana look like the big winners\"\n    ),\n    tbl\n)\n\n\n\n\nTotal GABF Awards by State, Population Adjusted (1987 - 2020)\nWhen reviewing total awards received per capita, Colorado, Wyoming, Alaska, Oregon, & Montana look like the big winners\n\n\n\n\n\n\nColorado is a great state for beer, but I would not expect it to be distinguished as a clear leader among the states. Similar story with Wyoming. Again, the data set does not provide information regarding participation. I suspect there is skew in the number of awards won by state because the festival is always held in Denver. Breweries located closer to Denver are more likely to participate.\nSeparately, time obviously plays a significant role that is not captured by the above table. The festival is older than most of the breweries that participated in 2020. The competition in 2020 was probably completely different, more crowded, than it was in 1987. When looking at total awards, we‚Äôre not accounting for that.\n\nBrief USA Beer History\nA little history on brewing in the US helps us better understand the time variable in the absencense of participation data. Jimmy Carter signed HR 1337 into law which made it explicitly legal to homebrew beer. When that law was passed, there were only ~50 breweries in the USA. Today, there are ~7k permitted breweries. You can read more in this interesting article on Vinepair. With that in mind, when the festival started breweries like Anheuser-Busch, Miller Brewing Company, and Coors Brewing Company controlled even more of the market share than they do today. The newcomers at that time were Boston Beer Company (i.e.¬†Sam Adams) and Alaskan Brewing Co., founded in 1984 and 1986 respectively. That history plays a significant role in our analysis because the newer breweries of today are years behind these older breweries with regard to winning awards. \n\n\n\nAnimated Map\nI visualized the award data in a Choropleth map. To capture the year data, I used gganimate to loop through and create a map for each year in a gif. To scale the color of the Choropleth by the specific year, rather than by the entire 34 years, I updated the awards_by_state function to include year (awards_by_state_year). It‚Äôs a bit of code to calculate different sums and counts for each level of aggregation and to impute records for missing years, but dplyr and tidyr do the heavy lifting. Nesting the annual observations in a data frame column keeps the data frame at 51 rows and prevents duplicating the simple features data for each year. The ggplot aesthetics will not take the nested data, but it‚Äôs easier to work with the data frame that way for other purposes and the function will probably be handy later. Below is the function spelled out.\n\n# Creates a column with the year total, every row with the same year has the same value\nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\")\n\n# Aggregates by year, state, and year total and counts the number of rows\nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\") %>% \n  group_by(state, year, year_total_awards) %>% \n  summarise(state_year_total_awards = n()) %>%\n  ungroup()\n\n# Joins missing states (from state.abb) and imputes the missing years and zero awards for each\nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\") %>% \n  group_by(state, year, year_total_awards) %>% \n  summarise(state_year_total_awards = n()) %>%\n  ungroup() %>% \n  full_join(tibble(state = state.abb), by = c(\"state\" = \"state\")) %>% \n  replace_na(list(year = 1987)) %>% \n  complete(state, nesting(year)) %>% \n  replace_na(list(state_year_total_awards = 0))\n\n# Imputes year_total_awards for the new years that were imputed in the last step  \nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\") %>% \n  group_by(state, year, year_total_awards) %>% \n  summarise(state_year_total_awards = n()) %>%\n  ungroup() %>% \n  full_join(tibble(state = state.abb), by = c(\"state\" = \"state\")) %>% \n  replace_na(list(year = 1987)) %>% \n  complete(state, nesting(year)) %>% \n  replace_na(list(state_year_total_awards = 0)) %>% \n  group_by(year) %>% \n  mutate(year_total_awards = max(year_total_awards, na.rm = T)) %>% \n  ungroup()\n\n# Calculate the percent of year total for each record (Choropleth fill) \nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\") %>% \n  group_by(state, year, year_total_awards) %>% \n  summarise(state_year_total_awards = n()) %>%\n  ungroup() %>% \n  full_join(tibble(state = state.abb), by = c(\"state\" = \"state\")) %>% \n  replace_na(list(year = 1987)) %>% \n  complete(state, nesting(year)) %>% \n  replace_na(list(state_year_total_awards = 0)) %>% \n  group_by(year) %>% \n  mutate(year_total_awards = max(year_total_awards, na.rm = T)) %>% \n  ungroup() %>% \n  mutate(pct_of_year_total_awards = state_year_total_awards / year_total_awards)\n\n# Finally, nest the yearly data under the state and join the alberusa data set and create the function\nawards_by_state_year <- . %>%\n  add_count(year, name = \"year_total_awards\") %>% \n  group_by(state, year, year_total_awards) %>% \n  summarise(state_year_total_awards = n()) %>%\n  ungroup() %>% \n  full_join(tibble(state = state.abb), by = c(\"state\" = \"state\")) %>% \n  replace_na(list(year = 1987)) %>% \n  complete(state, nesting(year)) %>% \n  replace_na(list(state_year_total_awards = 0)) %>% \n  group_by(year) %>% \n  mutate(year_total_awards = max(year_total_awards, na.rm = T)) %>% \n  ungroup() %>% \n  mutate(pct_of_year_total_awards = state_year_total_awards / year_total_awards) %>% \n  group_by(state) %>% \n  nest() %>%\n  right_join(albersusa::usa_sf(\"laea\"), by = c(\"state\"=\"iso_3166_2\"))\n\nThen we can plug the function and pipeline the data frame through and into a gganimate output.\n\nchorpleth <- gabf %>% \n  awards_by_state_year() %>% \n  unnest(data) %>% \n  ggplot(ggplot2::aes(geometry = geometry, fill = pct_of_year_total_awards, group = year)) +\n  geom_sf() +\n  scale_fill_viridis_c(option = \"magma\", alpha = .9, begin = .1, labels = scales::percent) + \n  labs(title = 'Percent of Total Awards by State, Year: {round(frame_time,0)}', fill = \"Awards\") +\n  theme_blog(axis.text = ggplot2::element_blank(),\n             axis.ticks = ggplot2::element_blank()) +\n  transition_time(year) +\n  ease_aes('linear')\nanimate(chorpleth, fps = 5)\n\n\n\n\n\n\nInteractive TIE Fighter Plot & Line Chart\nLooking at the animation, you can see Wisconsin has lost a proportion of total awards over the 34 years. This view does not provide clarity regarding where those proportions are going. To see the trend of awards for the state, I visualized a logistic regression model in a TIE fighter plot. A logistic regression model provides a useful summary for the 34 years of awards for each state, but I wanted to keep the annual context so I thought the TIE fighter plot would work better accompanied with a line chart. I decided to add in dynamic highlighting so that both visuals can be used interactively. I used crosstalk and plotly to build in the interactivity. Crosstalk enables htmlwidgets with cross-widget interactions (highlighting and filtering). Plotly builds interactive graphs and the author wrote a ggplotly() function that will convert ggplot2 graphics to plotly, brilliant! Now I can build interactive data visualizations without knowing much more than ggplot."
  }
]